{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da8674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import re \n",
    "import string \n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03aee5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore') #warning Î©îÏãúÏßÄ ÏïàÎ≥¥Ïù¥Í≤å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "616d85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "#Íµ¨ÎèÖ ÎßéÏùÄ Ïàú\n",
    "# office_data=[['Ï§ëÏïôÏùºÎ≥¥','025'],['JTBC','437'],['YTN','052'],['ÌïúÍµ≠Í≤ΩÏ†ú','015'],['Îß§ÏùºÍ≤ΩÏ†ú','009'],\n",
    "#             ['Ï°∞ÏÑ†ÏùºÎ≥¥','023'],['Ïó∞Ìï©Îâ¥Ïä§','422'],['SBS','055'],['KBS','056'],['ÌïúÍ≤®Î†à','028']]\n",
    "\n",
    "#Í≤ΩÏ†úÏßÄ\n",
    "# office_data=[['Îß§ÏùºÍ≤ΩÏ†ú','009'],['Î®∏ÎãàÌà¨Îç∞Ïù¥','008'],['ÎπÑÏ¶àÎãàÏä§ÏõåÏπò','648'],['ÏÑúÏö∏Í≤ΩÏ†ú','011'],\n",
    "#              ['ÏïÑÏãúÏïÑÍ≤ΩÏ†ú','277'],['Ïù¥Îç∞ÏùºÎ¶¨','018'],['Ï°∞ÏÑ†ÎπÑÏ¶à','366'],['Ï°∞ÏÑ∏ÏùºÎ≥¥','123'],['ÌååÏù¥ÎÇ∏ÏÖúÎâ¥Ïä§','014'],['ÌïúÍµ≠Í≤ΩÏ†ú','015'],\n",
    "#             ['Ìó§Îü¥ÎìúÍ≤ΩÏ†ú','016']]\n",
    "\n",
    "office_list=pd.DataFrame(office_data,columns=['Ïñ∏Î°†ÏÇ¨Î™Ö','id'])\n",
    "\n",
    "date_list=pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd2dee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_contents(url,headers):\n",
    "    url=\"https://news.naver.com\"+url\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    text=driver.page_source #Î∏åÎùºÏö∞Ï†ÄÏóê Î≥¥Ïù¥Îäî html Î¨∏ÏÑú Í∑∏ÎåÄÎ°úÏùò htmlÏùÑ Í∑∏ÎåÄÎ°ú Í∞ÄÏ†∏Ïò¥\n",
    "    \n",
    "    soup=BeautifulSoup(text,'html.parser')\n",
    "    \n",
    "    try:\n",
    "        title=soup.select_one('#articleTitle').text.strip() #Í∏∞ÏÇ¨ ÌÉÄÏù¥ÌãÄ \n",
    "\n",
    "        soup.select_one('#articleBodyContents').script.decompose()\n",
    "    #     contents=soup.select_one('#articleBodyContents').text.strip()#Í∏∞ÏÇ¨ Î≥∏Î¨∏ ÎÇ¥Ïö© \n",
    "    #     contents=clean_text(contents) #contents ÎÇ¥Ïö© Ï†ïÎ¶¨\n",
    "\n",
    "        like=soup.select_one('#spiLayer > div._reactionModule.u_likeit > ul > li.u_likeit_list.good > a > span.u_likeit_list_count._count').text\n",
    "        warm = soup.select_one('#spiLayer > div._reactionModule.u_likeit > ul > li.u_likeit_list.warm > a > span.u_likeit_list_count._count').text\n",
    "        sad = soup.select_one('#spiLayer > div._reactionModule.u_likeit > ul > li.u_likeit_list.sad > a > span.u_likeit_list_count._count').text\n",
    "        angry =soup.select_one('#spiLayer > div._reactionModule.u_likeit > ul > li.u_likeit_list.angry > a > span.u_likeit_list_count._count').text\n",
    "\n",
    "        response=requests.get(url,headers=headers,verify=False)#SSLError Î∞úÏÉùÏúºÎ°ú verifyÍ∞íÏùÄ FalseÎ°ú ÏÑ§Ï†ï\n",
    "        root=lxml.html.fromstring(response.content) \n",
    "        body=[]\n",
    "        for text in  root.xpath('//*[@id=\"articleBodyContents\"]/text()'):\n",
    "            body.append(text)\n",
    "\n",
    "        contents=' '.join(body)\n",
    "        contents=clean_text(contents) #contents ÎÇ¥Ïö© Ï†ïÎ¶¨\n",
    "        \n",
    "    except AttributeError:\n",
    "        title=None; contents=None; like='0'; warm='0'; sad='0'; angry='0'\n",
    "        \n",
    "    return title,contents,url,like,warm,sad,angry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae3a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(tmp):\n",
    "    punc = '[!\"#$%&\\'()*+,-./:;<=>?[\\]^_`{|}~‚Äú‚Äù¬∑]'\n",
    "    reg = re.compile('[a-zA-Z0-9+-_.]+@[a-zA-Z0-9-]+[a-zA-Z0-9-.]+$')\n",
    "    \n",
    "    tmp = re.sub(\n",
    "        '[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>‚ñ∂‚ñΩ‚ô°‚óÄ‚îÅ@\\#$%&\\\\\\=\\(\\'\\\"‚ìí(\\n)(\\t)]', ' ', tmp)\n",
    "    tmp = tmp.replace(\n",
    "        \"üá≤\\u200büáÆ\\u200büá±\\u200büá±\\u200büáÆ\\u200büá™\\u200b\", \"\")\n",
    "    \n",
    "    tmp = tmp.replace(\"Ïò§Î•òÎ•º Ïö∞ÌöåÌïòÍ∏∞ ÏúÑÌïú Ìï®Ïàò Ï∂îÍ∞Ä \", \"\")\n",
    "    tmp = tmp.replace(\"Î¨¥Îã® Ï†ÑÏû¨ Î∞è Ïû¨Î∞∞Ìè¨ Í∏àÏßÄ\", \"\")\n",
    "    tmp = tmp.replace(\"ÎèôÏòÅÏÉÅ Îâ¥Ïä§ \", \"\")\n",
    "    tmp = tmp.replace(\"ÏïµÏª§\", \"\")\n",
    "    tmp = tmp.replace('http','')\n",
    "    tmp = tmp.replace('Í∏∞Ïûê','')\n",
    "    tmp = tmp.replace('www','')\n",
    "    tmp = tmp.replace('co','')\n",
    "    tmp = tmp.replace('kr','')\n",
    "    tmp = tmp.replace('Ïò®ÎùºÏù∏ Ï†úÎ≥¥','')\n",
    "    \n",
    "    tmp=re.sub(punc,'',tmp)\n",
    "    tmp=re.sub(reg,'',tmp)\n",
    "    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d810c817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sttoint(string):\n",
    "    if re.search(',',string): \n",
    "        string=string.replace(',','')\n",
    "    \n",
    "    return int(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e7c3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_index(like,warm,sad,angry):\n",
    "    label=0\n",
    "    \n",
    "    SumPos=like+warm\n",
    "    SumNeg=sad+angry\n",
    "    \n",
    "    SumTotal=SumPos+SumNeg\n",
    "    Diff=SumPos-SumNeg\n",
    "    \n",
    "    try:\n",
    "        index=(Diff/SumTotal)*100+100\n",
    "    except ZeroDivisionError: #Î∂ÑÎ™®Í∞Ä 0Ïù¥ ÎêòÎäî ÏÉÅÌô©ÏóêÏÑú indexÎäî 100ÏúºÎ°ú ÏÑ§Ï†ï\n",
    "        index=100\n",
    "        \n",
    "    if index > 100: label=1\n",
    "    elif index==100: label=0\n",
    "    else: label=-1\n",
    "        \n",
    "    return index,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9597e18c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#main\n",
    "df_DataSpec=pd.DataFrame()\n",
    "df_DataSpec.rename(columns={'Ïñ∏Î°†ÏÇ¨ Î™Ö','Ï†ÑÏ≤¥ Îâ¥Ïä§ Í∏∞ÏÇ¨ Ïàò','Í∏çÏ†ï Í∏∞ÏÇ¨ Ïàò','Î∂ÄÏ†ï Í∏∞ÏÇ¨ Ïàò'})\n",
    "\n",
    "df_ErrorData=pd.DataFrame()\n",
    "df_ErrorData.rename(columns={'Ïñ∏Î°†ÏÇ¨ Î™Ö','ÎÇ†Ïßú','url'})\n",
    "\n",
    "for office_id in office_list['id']:\n",
    "    office_name=office_list.loc[office_list['id']==office_id,['Ïñ∏Î°†ÏÇ¨Î™Ö']].values[0] #Ïñ∏Î°†ÏÇ¨Î™Ö \n",
    "    office_name=office_name[0]\n",
    "    \n",
    "    TotalCount=0\n",
    "    PosCount=0\n",
    "    NegCount=0\n",
    "    \n",
    "    for date in date_list['Date']:\n",
    "        count=0\n",
    "        url = \"https://news.naver.com/main/ranking/office.nhn?officeId={}&date={}\".format(office_id,date)\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "        response=requests.get(url,headers=headers,verify=False)\n",
    "        root=lxml.html.fromstring(response.content)\n",
    "        url_contents=[]\n",
    "        df_total=pd.DataFrame()\n",
    "        df_total.rename(columns={'Date','Title','Contents','URL','Like','Warm','Sad','Angry','Index','Label'})\n",
    "\n",
    "        for i in range(2,4):\n",
    "            path='//*[@id=\"wrap\"]/div[4]/div[2]/div['+str(i)+']/ul/li'\n",
    "            url_contents=[]\n",
    "            \n",
    "            if i==2: category=\"ÎßéÏù¥ Î≥∏ Îâ¥Ïä§\"\n",
    "            else: category=\"ÎåìÍ∏Ä ÎßéÏùÄ Îâ¥Ïä§\"\n",
    "                \n",
    "            for li in root.xpath(path):\n",
    "                div=li.xpath('div/a')[0]\n",
    "                \n",
    "                url_content=div.get('href')\n",
    "                url_contents.append(url_content)\n",
    "                \n",
    "            for url in url_contents:\n",
    "                \n",
    "                count+=1\n",
    "                print(count,date,url)\n",
    "                title,contents,url,like,warm,sad,angry=get_news_contents(url,headers)\n",
    "                \n",
    "                if title is not None: \n",
    "                    like=sttoint(like); warm=sttoint(warm); sad=sttoint(sad); angry=sttoint(angry)\n",
    "                    index,label=get_sentiment_index(like,warm,sad,angry)\n",
    "\n",
    "                    if label >0 : PosCount+=1\n",
    "                    else: NegCount+=1\n",
    "\n",
    "                    df_tmp=pd.DataFrame({'Category':[category],'Date':[date],'Title':[title],'Contents':[contents],'URL':[url],\n",
    "                                                'Like':[like],'Warm':[warm],'Sad':[sad],'Angry':[angry],'Index':[index],'Label':[label]})\n",
    "\n",
    "                    df_total=df_total.append(df_tmp,ignore_index=True)\n",
    "                    TotalCount+=1\n",
    "                else: \n",
    "                    df_tmp=pd.DataFrame({'Ïñ∏Î°†ÏÇ¨ Î™Ö':[office_name],'date':[date],'url':[url]})\n",
    "                    df_ErrorData=df_ErrorData.append(df_tmp,ignore_index=True)\n",
    "                    print('error')\n",
    "                    \n",
    "        df_total.to_excel('file_name'+'.xlsx')\n",
    "    \n",
    "    df_tmp=pd.DataFrame({'Ïñ∏Î°†ÏÇ¨ Î™Ö':[office_name],'Ï†ÑÏ≤¥ Îâ¥Ïä§ Í∏∞ÏÇ¨ Ïàò':[TotalCount],'Í∏çÏ†ï Í∏∞ÏÇ¨ Ïàò':[PosCount],'Î∂ÄÏ†ï Í∏∞ÏÇ¨ Ïàò':[NegCount]})\n",
    "    df_DataSpec=df_DataSpec.append(df_tmp,ignore_index=True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykernel",
   "language": "python",
   "name": "pykernel3.7.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
