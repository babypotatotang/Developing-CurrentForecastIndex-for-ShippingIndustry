{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b79fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwons\\anaconda3\\envs\\pykernel3.7.3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from gensim import corpora, models\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b441c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#날짜별 수집을 위한 Dates 리스트 준비(2016.09~2021.09)\n",
    "read_file=\"C:\\\\Users\\\\User\\\\Desktop\\\\뉴스데이터 수집\\\\RawData\\\\Date_Filter\\\\Date.xlsx\"\n",
    "\n",
    "data=pd.read_excel(read_file)\n",
    "Dates=data.values.tolist()\n",
    "Dates=sum(Dates,[]) #날짜 데이터 준비\n",
    "Dates=list(map(str,Dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8dc46c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(common_texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]\n",
    "\n",
    "# Train the model on the corpus.\n",
    "lda = LdaModel(common_corpus, num_topics=80)\n",
    "\n",
    "#save model to disk\n",
    "tmp=datapath('model') \n",
    "lda.save(tmp)\n",
    "\n",
    "#load a potentially pretrained model from disk\n",
    "lda=LdaModel.load(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44582750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_topics(model, num_topics,num_words):\n",
    "    word_dict = {};\n",
    "    for i in range(num_topics):\n",
    "        words = model.show_topic(i, topn=num_words); #반환하는 토픽 연관어 개수 \n",
    "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = [i[0] for i in words];\n",
    "    return pd.DataFrame(word_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a480ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Document Ready\n"
     ]
    }
   ],
   "source": [
    "#데이터셋 준비document=[] #토픽 분석하고자 하는 문서\n",
    "\n",
    "for i in range(0,61):\n",
    "    #read_file=\"C:\\\\Users\\\\User\\\\Desktop\\\\뉴스데이터 수집\\\\RawData\\\\Filtered\\\\(A)해운업\\\\NewsResult_\"+Dates[i]+\"-\"+Dates[i+1]+\".xlsx\"\n",
    "    #read_file=\"C:\\\\Users\\\\User\\\\Desktop\\\\뉴스데이터 수집\\\\RawData\\\\Filtered\\\\(B)해운,선원,선사,선박,컨테이너,해사안전\\\\NewsResult_\"+Dates[i]+\"-\"+Dates[i+1]+\".xlsx\"\n",
    "    read_file=\"C:\\\\Users\\\\User\\\\Desktop\\\\뉴스데이터 수집\\\\RawData\\\\Filtered\\\\(C)해운\\\\NewsResult_\"+Dates[i]+\"-\"+Dates[i+1]+\".xlsx\"\n",
    " \n",
    "    data=pd.read_excel(read_file,usecols=[2]) #14열: 키워드\n",
    "    tmp_document=data.values.tolist()\n",
    "    tmp_document=sum(tmp_document,[])\n",
    "    document=document+tmp_document\n",
    "\n",
    "print(\"Document Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f93606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hh\n",
      "**Corpus Ready\n"
     ]
    }
   ],
   "source": [
    "#Corpus Ready\n",
    "data_word=[[word for word in x.split(' ')] for x in document] \n",
    "id2word=corpora.Dictionary(data_word)\n",
    "\n",
    "texts=data_word\n",
    "corpus=[id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "print(\"Corpus Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aed54297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**lda done, please wait\n",
      "**Result_out\n"
     ]
    }
   ],
   "source": [
    "lda = LdaModel(corpus=corpus, id2word=id2word, num_topics=80)\n",
    "print(\"lda done, please wait\")\n",
    "df=get_lda_topics(lda,num_topics,num_words).transpose()\n",
    "df.to_excel(write_file)\n",
    "\n",
    "print(\"Result_out\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykernel",
   "language": "python",
   "name": "pykernel3.7.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
